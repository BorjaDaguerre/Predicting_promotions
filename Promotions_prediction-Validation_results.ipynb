{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b649ac9",
   "metadata": {},
   "source": [
    "### Using validation data to improve evaluation metrics\n",
    "\n",
    "This notebook contains various approaches used to enhance evaluation metrics in the notebook available at (https://github.com/BorjaDaguerre/Predicting_promotions/blob/main/Promotions_prediction.ipynb) using validation data. The original dataset lacked features that exhibited significant correlation with the target variable. Therefore, the objective was to explore distinct machine learning methods to preprocess the input data utilized by our models. This exploration aimed to uncover or amplify potential 'signals' within the data. Three different methods were employed to enhance evaluation metrics, yielding the following outcomes:\n",
    "\n",
    "* Scaling: This conventional technique aims to bring various features within a consistent range. It can benefit specific ML methods by rendering data and potential relationships more manageable. In this case, all non-dummy features were scaled; however, no discernible improvement in evaluation performance was observed.\n",
    "\n",
    "* Under/Oversampling: This method involves identifying underrepresented or overrepresented classes or data instances in the dataset. It adjusts the instance count based on their status to mitigate class imbalance issues, as evident in the current dataset. This approach allows better utilization of patterns within the data due to the increased or decreased presence of minority/majority classes. Both under and oversampling methods were applied, yielding diverse outcomes. While undersampling significantly improved Recall at the expense of decreased Accuracy, thus proving effective for minimizing false negatives (FN), oversampling exhibited an overall decline in metrics.\n",
    "\n",
    "* RFE (Recursive Feature Elimination): RFE employs cross-validation to iteratively eliminate irrelevant features that could introduce noise to the prediction process. It retains informative features to predict classification values. In our case, 29 features were retained out of the initial 60 (a result of one-hot encoding). Eliminated features primarily consisted of dummy variables ('region_1', 'region_2', etc.) as well as 'gender'. RFE resulted in a minor accuracy reduction while maintaining consistent values for other metrics. Given the similarity to the original results and its potential for generating a more parsimonious and less overfit model, this method will be implemented and compared against the original in test set evaluations.\n",
    "\n",
    "Based on these results, for the test evaluation we will use the scaled model with no additional preprocessing and a undersampler given the good results with the recall metric.\n",
    "\n",
    "\n",
    "### Dataset information \n",
    "\n",
    "Features included:\n",
    "\n",
    "* employee_id: employee id\n",
    "* department: name of the deparment the employee works at\n",
    "* region: number of the region the employee works at, ranges from 1 to 34\n",
    "* education: level of education the employee has\n",
    "* gender: gender of teh employee\n",
    "* recruitment_channel: which method was used to recruit the employee\n",
    "* no_of_trainings: number of training the employee has had, ranging from 1 to 10\n",
    "* age: age of the employee\n",
    "* previous_year_rating: work rating the employee obtained one year before, ranges from 1 to 5\n",
    "* length_of_service: number of years the employee has worked on the company\n",
    "* KPIs_met >80%: indicates if the Key Performance Indicators were met above a 80% threshold \n",
    "* awards_won?: indicates if the employee has won an award while working on the company\n",
    "* avg_training_score: average score of the training processes performed while in the company\n",
    "* is_promoted: our target variable, indicates if the employee has been promoted or not\n",
    "\n",
    "\n",
    "Hope you enjoy it! Any feedback is welcome at borjadaguerre@gmail.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc46a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import json\n",
    "import seaborn as sns\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa10411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set does not contain target values, train set has been split into train a test to account for it\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\gebruiker\\Documents\\DataScience\\DatasSets\\train_LZdllcl.csv')\n",
    "validation_set = df[:int(len(df) * 0.75)]\n",
    "validation = int(len(validation_set) * 0.75)\n",
    "validation_train = validation_set[:validation]\n",
    "validation_test = validation_set[validation:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e4de43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping 'employer_id' becuase is irrelevant\n",
    "\n",
    "validation_train = validation_train.drop(columns = ['employee_id'])\n",
    "validation_test = validation_test.drop(columns = ['employee_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78d43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the NaN vallues of the feature education with the 'Unknoww' value\n",
    "\n",
    "validation_train['education'].fillna('Unknown', inplace=True)\n",
    "validation_test['education'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7db6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first split of categorical and numerical vairables \n",
    "\n",
    "categorical = validation_train.select_dtypes(include=['object'])\n",
    "numerical = validation_train.select_dtypes(include=['int64','float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6806aefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the categorical columns\n",
    "one_hot_encoded_train = pd.get_dummies(validation_train[categorical.columns], prefix=categorical.columns)\n",
    "one_hot_encoded_test = pd.get_dummies(validation_test[categorical.columns], prefix=categorical.columns)\n",
    "\n",
    "\n",
    "# Concatenate the one-hot encoded columns to the original DataFrame\n",
    "validation_train = pd.concat([validation_train, one_hot_encoded_train], axis=1)\n",
    "validation_test = pd.concat([validation_test, one_hot_encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92498a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3334503457717557 3.3276931161324224\n"
     ]
    }
   ],
   "source": [
    "# No significant differences across the 'train['previous_year_rating'].mean()' values, imputation has been done along the whole \n",
    "# training set disregarding the train/validation split in this instance\n",
    "\n",
    "print(validation_train['previous_year_rating'].mean(), validation_test['previous_year_rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767ef591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing the NaN values of 'previouos_year_rating' with the training mean, interpolation with through linear method also \n",
    "#available since 'previouos_year_rating' is lighly correlated with 'KPI_met > 80%'\n",
    "\n",
    "validation_train['previous_year_rating'].fillna(int(validation_train['previous_year_rating'].mean()), inplace = True)\n",
    "validation_test['previous_year_rating'].fillna(int(validation_test['previous_year_rating'].mean()), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d73d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotions = ['Yes' if i == 1 else 'No' for  i in validation_train['is_promoted']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb6a4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the numerical features to use or models on. Categorical features have been one-hot encoded before\n",
    "\n",
    "validation_train  = validation_train.select_dtypes(include=['int64','float64','uint8'])\n",
    "validation_test = validation_test.select_dtypes(include = ['int64', 'float64', 'uint8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156228ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dummies = [col for col in validation_train.columns if len(np.unique(validation_train[col])) > 2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "validation_train_scaled = pd.DataFrame(data = scaler.fit_transform(validation_train[non_dummies]), columns = non_dummies)\n",
    "validation_train = validation_train.drop(columns = non_dummies)\n",
    "validation_train = validation_train.join(validation_train_scaled)\n",
    "\n",
    "validation_test_scaled = pd.DataFrame(data = scaler.fit_transform(validation_test[non_dummies]), columns = non_dummies)\n",
    "validation_test = validation_test.drop(columns = non_dummies)\n",
    "validation_test.index = validation_test_scaled.index\n",
    "validation_test = validation_test.join(validation_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5172e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing into train, validation, and test\n",
    "\n",
    "X_train_val = validation_train.drop('is_promoted',axis = 1)\n",
    "y_train_val = validation_train['is_promoted']\n",
    "X_test_val = validation_test.drop('is_promoted',axis = 1)\n",
    "y_test_val = validation_test['is_promoted']\n",
    "\n",
    "validation_raw = X_train_val, y_train_val, X_test_val, y_test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46a444b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the oversampler\n",
    "oversampler = RandomOverSampler()\n",
    "undersampler = RandomUnderSampler()\n",
    "\n",
    "# Oversample the minority class\n",
    "X_train_val_oversampled, y_train_val_oversampled = oversampler.fit_resample(X_train_val, y_train_val)\n",
    "\n",
    "\n",
    "# Undersample the majority class\n",
    "X_train_val_undersampled, y_train_val_undersampled = undersampler.fit_resample(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73821c26",
   "metadata": {},
   "source": [
    "He have a couple of features with good correaltinal coefficients and a lot with low coefficient values, let's try some validation testing to see how they'll affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21473182",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 4\n",
    "\n",
    "\n",
    "# Define the base models to be trained and evaluated\n",
    "base_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(random_state=random_state),\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=random_state),\n",
    "    \"BaggingClassifier\": BaggingClassifier(random_state=random_state),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=random_state),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c544dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_train, y_train, X_test, y_test ):\n",
    "\n",
    "    \n",
    "    results = pd.DataFrame(columns=['training_accuracy',\"Accuracy\", \"Recall\", \"Precision\", \"F1\"])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        training_accuracy= round(score,3)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred),3)\n",
    "        recall = round(recall_score(y_test, y_pred),3)\n",
    "        precision = round(precision_score(y_test, y_pred),3)\n",
    "        f1 = round(f1_score(y_test, y_pred),3)\n",
    "\n",
    "        results.loc[f\"{model_name} \"] = [training_accuracy, accuracy, recall, precision, f1]\n",
    "        \n",
    "\n",
    "    results.sort_values(by=\"F1\", ascending=False, inplace=True)\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b263362",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 4\n",
    "\n",
    "\n",
    "# Define the base models to be trained and evaluated\n",
    "models_rfe = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(random_state=random_state),\n",
    "    \"XGBClassifier\": XGBClassifier(random_state=random_state),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=random_state),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a9e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_rfe(models, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    \n",
    "    results_rfe = pd.DataFrame(columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\", 'number_of_features'])\n",
    "\n",
    "    for model_name, model in models_rfe.items():\n",
    "        \n",
    "        rfe = RFE(model, n_features_to_select=None)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred),3)\n",
    "        recall = round(recall_score(y_test, y_pred),3)\n",
    "        precision = round(precision_score(y_test, y_pred),3)\n",
    "        f1 = round(f1_score(y_test, y_pred),3)\n",
    "        number_of_features = len(selected_features)\n",
    "\n",
    "        results_rfe.loc[f\"{model_name} \"] = [accuracy, recall, precision, f1, number_of_features]\n",
    "        \n",
    "\n",
    "    results_rfe.sort_values(by=\"F1\", ascending=False, inplace=True)\n",
    "    return results_rfe, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "731d336c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             training_accuracy  Accuracy  Recall  Precision  \\\n",
       "XGBClassifier                            0.952     0.941   0.380      0.886   \n",
       "BaggingClassifier                        0.991     0.931   0.364      0.710   \n",
       "GradientBoostingClassifier               0.939     0.937   0.287      0.966   \n",
       "Random Forest Classifier                 1.000     0.931   0.266      0.842   \n",
       "Logistic Regression                      0.933     0.930   0.253      0.841   \n",
       "\n",
       "                                F1  \n",
       "XGBClassifier                0.532  \n",
       "BaggingClassifier            0.482  \n",
       "GradientBoostingClassifier   0.442  \n",
       "Random Forest Classifier     0.404  \n",
       "Logistic Regression          0.389  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation raw \n",
    "val_raw = evaluate_models(base_models, X_train_val, y_train_val, X_test_val, y_test_val)\n",
    "val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def7cdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                             Accuracy  Recall  Precision     F1  \\\n",
       " XGBClassifier                   0.941   0.380      0.886  0.532   \n",
       " GradientBoostingClassifier      0.937   0.287      0.966  0.442   \n",
       " Random Forest Classifier        0.931   0.266      0.842  0.404   \n",
       " Logistic Regression             0.930   0.253      0.841  0.389   \n",
       " \n",
       "                              number_of_features  \n",
       " XGBClassifier                              29.0  \n",
       " GradientBoostingClassifier                 29.0  \n",
       " Random Forest Classifier                   29.0  \n",
       " Logistic Regression                        29.0  ,\n",
       " Index(['KPIs_met >80%', 'awards_won?', 'department_Analytics',\n",
       "        'department_Finance', 'department_HR', 'department_Operations',\n",
       "        'department_Procurement', 'department_R&D',\n",
       "        'department_Sales & Marketing', 'department_Technology',\n",
       "        'region_region_17', 'region_region_22', 'region_region_25',\n",
       "        'region_region_27', 'region_region_28', 'region_region_3',\n",
       "        'region_region_4', 'region_region_5', 'region_region_7',\n",
       "        'region_region_9', 'education_Bachelor's', 'education_Master's & above',\n",
       "        'gender_f', 'recruitment_channel_referred', 'no_of_trainings', 'age',\n",
       "        'previous_year_rating', 'length_of_service', 'avg_training_score'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation raw with rfe\n",
    "validation_rfe = evaluate_models_rfe(base_models, X_train_val, y_train_val, X_test_val, y_test_val)\n",
    "validation_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05eb1312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             training_accuracy  Accuracy  Recall  Precision  \\\n",
       "XGBClassifier                            0.952     0.941   0.380      0.886   \n",
       "BaggingClassifier                        0.991     0.931   0.364      0.710   \n",
       "GradientBoostingClassifier               0.939     0.937   0.287      0.966   \n",
       "Random Forest Classifier                 1.000     0.931   0.266      0.842   \n",
       "Logistic Regression                      0.933     0.930   0.253      0.841   \n",
       "\n",
       "                                F1  \n",
       "XGBClassifier                0.532  \n",
       "BaggingClassifier            0.482  \n",
       "GradientBoostingClassifier   0.442  \n",
       "Random Forest Classifier     0.404  \n",
       "Logistic Regression          0.389  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation scaled\n",
    "\n",
    "val_scaled = evaluate_models(base_models, X_train_val, y_train_val, X_test_val, y_test_val)\n",
    "val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72827ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                             Accuracy  Recall  Precision     F1  \\\n",
       " XGBClassifier                   0.941   0.380      0.886  0.532   \n",
       " GradientBoostingClassifier      0.937   0.287      0.966  0.442   \n",
       " Random Forest Classifier        0.931   0.266      0.842  0.404   \n",
       " Logistic Regression             0.930   0.253      0.841  0.389   \n",
       " \n",
       "                              number_of_features  \n",
       " XGBClassifier                              29.0  \n",
       " GradientBoostingClassifier                 29.0  \n",
       " Random Forest Classifier                   29.0  \n",
       " Logistic Regression                        29.0  ,\n",
       " Index(['KPIs_met >80%', 'awards_won?', 'department_Analytics',\n",
       "        'department_Finance', 'department_HR', 'department_Operations',\n",
       "        'department_Procurement', 'department_R&D',\n",
       "        'department_Sales & Marketing', 'department_Technology',\n",
       "        'region_region_17', 'region_region_22', 'region_region_25',\n",
       "        'region_region_27', 'region_region_28', 'region_region_3',\n",
       "        'region_region_4', 'region_region_5', 'region_region_7',\n",
       "        'region_region_9', 'education_Bachelor's', 'education_Master's & above',\n",
       "        'gender_f', 'recruitment_channel_referred', 'no_of_trainings', 'age',\n",
       "        'previous_year_rating', 'length_of_service', 'avg_training_score'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation scaled with rfe\n",
    "val_scaled_rfe = evaluate_models_rfe(evaluate_models_rfe, X_train_val, y_train_val, X_test_val, y_test_val)\n",
    "val_scaled_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6728bedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             training_accuracy  Accuracy  Recall  Precision  \\\n",
       "BaggingClassifier                        0.991     0.786   0.803      0.263   \n",
       "XGBClassifier                            0.941     0.772   0.846      0.257   \n",
       "Logistic Regression                      0.787     0.766   0.816      0.247   \n",
       "Random Forest Classifier                 1.000     0.748   0.866      0.240   \n",
       "GradientBoostingClassifier               0.824     0.718   0.947      0.230   \n",
       "\n",
       "                                F1  \n",
       "BaggingClassifier            0.397  \n",
       "XGBClassifier                0.394  \n",
       "Logistic Regression          0.379  \n",
       "Random Forest Classifier     0.376  \n",
       "GradientBoostingClassifier   0.370  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation with under/oversampling\n",
    "\n",
    "val_undersampled =evaluate_models(base_models, X_train_val_undersampled, y_train_val_undersampled, X_test_val, y_test_val)\n",
    "val_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b19814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             training_accuracy  Accuracy  Recall  Precision  \\\n",
       "Random Forest Classifier                 1.000     0.927   0.366      0.643   \n",
       "BaggingClassifier                        1.000     0.919   0.406      0.547   \n",
       "XGBClassifier                            0.922     0.833   0.744      0.311   \n",
       "Logistic Regression                      0.792     0.766   0.813      0.247   \n",
       "GradientBoostingClassifier               0.820     0.718   0.951      0.230   \n",
       "\n",
       "                                F1  \n",
       "Random Forest Classifier     0.466  \n",
       "BaggingClassifier            0.466  \n",
       "XGBClassifier                0.439  \n",
       "Logistic Regression          0.378  \n",
       "GradientBoostingClassifier   0.371  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_oversampled = evaluate_models(base_models, X_train_val_oversampled, y_train_val_oversampled, X_test_val, y_test_val)\n",
    "val_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48bae759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                             Accuracy  Recall  Precision     F1  \\\n",
       " Random Forest Classifier        0.927   0.366      0.643  0.466   \n",
       " XGBClassifier                   0.833   0.744      0.311  0.439   \n",
       " Logistic Regression             0.766   0.813      0.247  0.378   \n",
       " GradientBoostingClassifier      0.718   0.951      0.230  0.371   \n",
       " \n",
       "                              number_of_features  \n",
       " Random Forest Classifier                   29.0  \n",
       " XGBClassifier                              29.0  \n",
       " Logistic Regression                        29.0  \n",
       " GradientBoostingClassifier                 29.0  ,\n",
       " Index(['KPIs_met >80%', 'awards_won?', 'department_Analytics',\n",
       "        'department_Finance', 'department_HR', 'department_Operations',\n",
       "        'department_Procurement', 'department_R&D',\n",
       "        'department_Sales & Marketing', 'department_Technology',\n",
       "        'region_region_22', 'region_region_26', 'region_region_28',\n",
       "        'region_region_29', 'region_region_31', 'region_region_32',\n",
       "        'region_region_34', 'region_region_4', 'region_region_6',\n",
       "        'region_region_8', 'region_region_9', 'education_Bachelor's',\n",
       "        'education_Master's & above', 'gender_f',\n",
       "        'recruitment_channel_referred', 'age', 'previous_year_rating',\n",
       "        'length_of_service', 'avg_training_score'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_oversampled_rfe = evaluate_models_rfe(models_rfe, X_train_val_oversampled, y_train_val_oversampled, X_test_val, y_test_val)\n",
    "val_oversampled_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3709316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                             Accuracy  Recall  Precision     F1  \\\n",
       " XGBClassifier                   0.772   0.846      0.257  0.394   \n",
       " Logistic Regression             0.766   0.816      0.247  0.379   \n",
       " Random Forest Classifier        0.748   0.866      0.240  0.376   \n",
       " GradientBoostingClassifier      0.718   0.947      0.230  0.370   \n",
       " \n",
       "                              number_of_features  \n",
       " XGBClassifier                              29.0  \n",
       " Logistic Regression                        29.0  \n",
       " Random Forest Classifier                   29.0  \n",
       " GradientBoostingClassifier                 29.0  ,\n",
       " Index(['KPIs_met >80%', 'awards_won?', 'department_Analytics',\n",
       "        'department_Finance', 'department_HR', 'department_Operations',\n",
       "        'department_Procurement', 'department_R&D',\n",
       "        'department_Sales & Marketing', 'department_Technology',\n",
       "        'region_region_15', 'region_region_16', 'region_region_17',\n",
       "        'region_region_21', 'region_region_22', 'region_region_26',\n",
       "        'region_region_28', 'region_region_31', 'region_region_4',\n",
       "        'region_region_7', 'region_region_8', 'education_Bachelor's',\n",
       "        'education_Master's & above', 'gender_f',\n",
       "        'recruitment_channel_referred', 'age', 'previous_year_rating',\n",
       "        'length_of_service', 'avg_training_score'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_undersampled_rfe = evaluate_models_rfe(models_rfe, X_train_val_undersampled, y_train_val_undersampled, X_test_val, y_test_val)\n",
    "val_undersampled_rfe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
